
```{r}
#Loading packages
pacman::p_load("rstan", "tidyverse", "ggplot2", "reshape2", "cmdstanr", "posterior", "brms", "boot")
```

**Defining the agents**
```{r}
#Defining a Win-Stay-Lose-Shift with a rulefollowing parameter agent function
WSLSAgent_f <- function(prevChoice, Feedback, ruleFollowing) {
  if (ruleFollowing != 0){
    
    if (prevChoice == 0) {
      prevChoice == -1 }
  
    if (Feedback == 1) { #If feedback = 1 (win), stay
      rate = prevChoice*ruleFollowing
    }
    
    else if (Feedback == 0) { #If feedback = 0 (loss), shift
      rate = (-prevChoice)*ruleFollowing
    }
    
    rate = (1/2)*(rate + 1) #we needed -1 to become 0 and 1 to stay 1, also -0.5 will be 0.25 and 0.5 will be 0.75. 
  }
  
  else { rate = 0.5}
  
  choice <- rbinom(1, 1, rate)

  return(choice)
}


#Defining a random agent function
RandomAgent_f <- function(rate){
  choice <- rbinom(1, 1, rate)
  return(choice)
}

```


**Simulate data**
```{r}
#Define rate
random_rate <- 0.5

#Define ruleFollowing parameter value
ruleFollowing <- 0.8

#Define number of trials
trials = 120

#Define empty vectors
Self <- rep(NA, trials)
Other <- rep(NA, trials)

#Define random first choice for player
Self[1] <- RandomAgent_f(0.5) #player

#Run simulation
for (t in seq(trials)){Other[t] <- RandomAgent_f(random_rate)}

for (i in 2:trials){
  if (Self[i-1] == Other[i-1]){
    Feedback = 1
} else {Feedback = 0}
  Self[i] <- WSLSAgent_f(Self[i-1], Feedback, ruleFollowing)
}

```


**Transforming the data to the appropriate form**
```{r}
#Create empty column with strategy choice (i.e. what self should do according to the WSLS strategy)
df$strategy_choice <- NA

#Add strategy choices (1 = right, -1 = left)
df$strategy_choice[df$Other == 1 & df$Self == 1] <- 1 #self wins on right, goes right
df$strategy_choice[df$Other == 1 & df$Self == 0] <- 1 #self loses on left, goes right
df$strategy_choice[df$Other == 0 & df$Self == 1] <- -1 #self loses on right, goes left
df$strategy_choice[df$Other == 0 & df$Self == 0] <- -1 #self wins on left, goes left

#Exclude first trial(no strategy in first round, it's random)
insert_value = NA
df = df %>%
   mutate(strategy_choice = lag(strategy_choice, n = 1, default = insert_value))
df = df[-1,]

#Transform data to lists
data <- list(
  n_trials = nrow(df),  # n of trials
  choice = df$Self, # sequence of choices
  strategy_choice = df$strategy_choice # whether or not agent is choosing right 
)
```


**Test module: Compile and fit the model for fixed parameter values**
```{r}
#collect stan model
file <- file.path("rulefollowing_agent.stan")
mod <- cmdstan_model(file, 
                     # this specifies we can parallelize the gradient estimations on multiple cores
                     cpp_options = list(stan_threads = TRUE), 
                     # this is a trick to make it faster
                     stanc_options = list("O1")) 

#extract samples
samples <- mod$sample(
  data = data, # the data :-)
  seed = 123,  # a seed, so I always get the same results
  chains = 2,  # how many chains should I fit (to check whether they give the same results)
  parallel_chains = 2, # how many of the chains can be run in parallel?
  threads_per_chain = 2, # distribute gradient estimations within chain across multiple cores
  iter_warmup = 1000,  # warmup iterations through which hyperparameters (steps and step length) are adjusted
  iter_sampling = 2000, # total number of iterations
  refresh = 0,  # how often to show that iterations have been run
  max_treedepth = 20, # how many steps in the future to check to avoid u-turns
  adapt_delta = 0.99, # how high a learning rate to adjust hyperparameters during warmup
)

#extract summary 
samples$summary()

samples$summary("ruleFollowing")

# Extract posterior samples and include sampling of the prior:
draws_df <- as_draws_df(samples$draws())

# Checking the model's chains (noise)
ggplot(draws_df, aes(.iteration,  ruleFollowing, group = .chain, color = .chain)) +
  geom_line() +
  theme_classic()

```

**Prior sensitivity analysis**
```{r}
pacman::p_load(
        here, 
        tidybayes,
        future,
        purrr,
        furrr)
plan(multisession, workers = 4)

#Adding different priors
prior_mean_rulefollowing <- seq(-2, 2, 1) 
prior_sd_rulefollowing <- seq(0.2, 1, 0.2)

priors <- tibble(expand.grid(tibble(prior_mean_rulefollowing, prior_sd_rulefollowing)))

sim_d_and_fit <- function(prior_mean_rulefollowing, prior_sd_rulefollowing) {
  
  #Transform data to lists
  data <- list(
  n_trials = nrow(df),  # n of trials
  choice = df$Self, # sequence of choices
  strategy_choice = df$strategy_choice, # whether or not agent is choosing right
  prior_mean_rulefollowing = prior_mean_rulefollowing,
  prior_sd_rulefollowing = prior_sd_rulefollowing
  )
    
  #Fetch model
  file <- file.path("rulefollowing_agent_test.stan")
  mod <- cmdstan_model(file, 
                       # this specifies we can parallelize the gradient estimations on multiple cores
                       cpp_options = list(stan_threads = TRUE), 
                       # this is a trick to make it faster
                       stanc_options = list("O1")) 
  
  samples <- mod$sample(
    data = data,
    seed = 1000,
    chains = 1,
    parallel_chains = 1,
    threads_per_chain = 1,
    iter_warmup = 1000,
    iter_sampling = 2000,
    refresh = 0,
    max_treedepth = 20,
    adapt_delta = 0.99,
    )
  
  draws_df <- as_draws_df(samples$draws()) 
  
  temp <- tibble(rulefollowing_prior = draws_df$rulefollowing_prior, 
                 
                 rulefollowing_posterior = draws_df$rulefollowing_posterior, 
                 
                 rulefollowing_prior_preds = draws_df$rulefollowing_prior_preds,
                 
                 rulefollowing_posterior_preds = draws_df$rulefollowing_posterior_preds,
 
                 prior_mean_rulefollowing = prior_mean_rulefollowing,
                 prior_sd_rulefollowing = prior_sd_rulefollowing)
    
    return(temp)
  
}

recovery_df <- future_pmap_dfr(priors, sim_d_and_fit, .options = furrr_options(seed = TRUE))
```

```{r}
#Plot beta posterior for varying priors
ggplot(recovery_df, aes(prior_sd_rulefollowing, rulefollowing_posterior)) +
  geom_point(alpha = 0.008) +
  geom_hline(yintercept = 0.69, color = "red") +
  geom_smooth(method = lm) +
  facet_wrap(.~prior_mean_rulefollowing) +
  ggtitle("Effect on rulefollowing posterior when varying the prior")
  theme_classic()

```



**Function for simulating with different parameter values for rulefollowing**
```{r}
#Simulating with different values for ruleFollowing 
list_of_dfs <- list()
temp <- list()
recovery_df <- data.frame()

#Looping through data simulation, model compilation, and chain checks for varying parameter values of rulefollowing
for(ruleFollowing_lvl in seq(0, 1, 0.2)){
  
  ruleFollowing = ruleFollowing_lvl
  trials = 120
  random_rate = 0.7
  
  #Define empty vectors
  Self <- rep(NA, trials)
  Other <- rep(NA, trials)
  
  #Define random first choice for player
  Self[1] <- RandomAgent_f(0.5) #player
  
  #Run simulation
  for (t in seq(trials)){Other[t] <- RandomAgent_f(random_rate)}
   
  for (i in 2:trials){
    if (Self[i-1] == Other[i-1]){
      Feedback = 1
  } else {Feedback = 0}
    Self[i] <- WSLSAgent_f(Self[i-1], Feedback, ruleFollowing)
  }

  #show
  df <- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other))
  
  list_of_dfs <- append(list_of_dfs, df)
  
  #empty column
  df$strategy_choice <- NA
  
  #Transform
  df$strategy_choice[df$Other == 1 & df$Self == 1] <- 1 #self wins on right, goes right
  df$strategy_choice[df$Other == 1 & df$Self == 0] <- 1 #self loses on left, goes right
  df$strategy_choice[df$Other == 0 & df$Self == 1] <- -1 #self loses on right, goes left
  df$strategy_choice[df$Other == 0 & df$Self == 0] <- -1 #self wins on left, goes left
  
  #exclude first trial
  insert_value = NA
  df = df %>%
     mutate(strategy_choice = lag(strategy_choice, n = 1, default = insert_value))
  df = df[-1,]
  
  #Transform to lists
  data <- list(
    n_trials = nrow(df),  # n of trials
    choice = df$Self, # sequence of choices
    strategy_choice = df$strategy_choice # whether or not agent is choosing right 
    )
  
  file <- file.path("rulefollowing_agent.stan")
  mod <- cmdstan_model(file, 
                       # this specifies we can parallelize the gradient estimations on multiple cores
                       cpp_options = list(stan_threads = TRUE), 
                       # this is a trick to make it faster
                       stanc_options = list("O1")) 
  
  #extract samples
  samples <- mod$sample(
    data = data, # the data :-)
    seed = 123,  # a seed, so I always get the same results
    chains = 2,  # how many chains should I fit (to check whether they give the same results)
    parallel_chains = 2, # how many of the chains can be run in parallel?
    threads_per_chain = 2, # distribute gradient estimations within chain across multiple cores
    iter_warmup = 1000,  # warmup iterations through which hyperparameters (steps and step length) are adjusted
    iter_sampling = 2000, # total number of iterations
    refresh = 0,  # how often to show that iterations have been run
    max_treedepth = 20, # how many steps in the future to check to avoid u-turns
    adapt_delta = 0.99, # how high a learning rate to adjust hyperparameters during warmup
  )
  
  #extract summary 
  samples$summary()
  
  # Extract posterior samples and include sampling of the prior:
  draws_df <- as_draws_df(samples$draws())
  
    
  temp2 <- tibble(ruleFollowingEst = (draws_df$ruleFollowing),
                  ruleFollowingTrue = ruleFollowing_lvl)
    
  if (exists("recovery_df_2")) {recovery_df_2 <- rbind(recovery_df_2, temp2)} else {recovery_df_2 <- temp2}

  
  # Checking the model's chains (noise)
  temp = ggplot(draws_df, aes(.iteration,  ruleFollowing, group = .chain, color = .chain)) +
      geom_line() +
      theme_classic()
  
  # assign function within loop
  assign(paste0("plot_", ruleFollowing_lvl), temp)

  assign(paste0("draws_df_", ruleFollowing_lvl), draws_df)
  
  recovery_df <- rbind(recovery_df, samples$summary("ruleFollowing"))
  
  #assign(paste0("recovery_", ruleFollowing_lvl), samples$summary("ruleFollowing"))
  
}

  
```


**Plots for different values of rulefollowing**
```{r}

#Create plot for rulefollowing 0.2
plot_0.2  <- plot_0.2 + ggtitle("Rule-following = 0.2")

#Add a prior for rulefollowing at level 0.2
draws_df_0.2<- draws_df_0.2 %>% mutate(
  ruleFollowing_prior = rbeta(nrow(draws_df_0.2), 1, 1)
)

#Plot the density for rulefollowing (prior and posterior)
p1 <- ggplot(draws_df_0.2) +
  geom_density(aes(ruleFollowing), fill = "blue", alpha = 0.3) +
  geom_density(aes(ruleFollowing_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.2, linetype = "dashed", color = "black", size = 1.5) +
  xlab("Rule-following") +
  ylab("Posterior Density") +
  ylim(0,6)+
  theme_classic()+
  ggtitle("True rule-following = 0.2")

#Create plot for rulefollowing 0.4
plot_0.4 <- plot_0.4 + ggtitle("Rule-following = 0.4")

#Add a prior for rulefollowing at level 0.4
draws_df_0.4<- draws_df_0.4 %>% mutate(
  ruleFollowing_prior = rbeta(nrow(draws_df_0.4), 1, 1)
)

#Plot the density for rulefollowing (prior and posterior)
p2 <- ggplot(draws_df_0.4) +
  geom_density(aes(ruleFollowing), fill = "blue", alpha = 0.3) +
  geom_density(aes(ruleFollowing_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.4, linetype = "dashed", color = "black", size = 1.5) +
  xlab("Rule-following") +
  ylab("Posterior Density") +
  ylim(0,6)+
  theme_classic()+
  ggtitle("True rule-following = 0.4")

#Create plot for rulefollowing 0.6
plot_0.6 <- plot_0.6 + ggtitle("Rule-following = 0.6")

#Add a prior for rulefollowing at level 0.6
draws_df_0.6<- draws_df_0.6 %>% mutate(
  ruleFollowing_prior = rbeta(nrow(draws_df_0.6), 1, 1)
)

#Plot the density for rulefollowing (prior and posterior)
p3 <- ggplot(draws_df_0.6) +
  geom_density(aes(ruleFollowing), fill = "blue", alpha = 0.3) +
  geom_density(aes(ruleFollowing_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.6, linetype = "dashed", color = "black", size = 1.5) +
  xlab("Rule-following") +
  ylab("Posterior Density") +
  ylim(0,6)+
  theme_classic()+
  ggtitle("True rule-following = 0.6")

#Create plot for rulefollowing 0.8
plot_0.8 <- plot_0.8 + ggtitle("Rule-following = 0.8")

#Add a prior for rulefollowing at level 0.6
draws_df_0.8<- draws_df_0.8 %>% mutate(
  ruleFollowing_prior = rbeta(nrow(draws_df_0.8), 1, 1)
)

#Plot the density for rulefollowing (prior and posterior)
p4 <- ggplot(draws_df_0.8) +
  geom_density(aes(ruleFollowing), fill = "blue", alpha = 0.3) +
  geom_density(aes(ruleFollowing_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.8, linetype = "dashed", color = "black", size = 1.5) +
  xlab("Rule-following") +
  ylab("Posterior Density") +
  ylim(0,6)+
  theme_classic()+
  ggtitle("True rule-following = 0.8")

  
#Plot chain convergence for varying alpha levels
ggarrange(plot_0.2 + rremove("x.text")+ rremove("xlab"), plot_0.4 + rremove("x.text")+ rremove("xlab")+ rremove("y.text") + rremove("ylab"), plot_0.6, plot_0.8 + rremove("y.text")+ rremove("ylab"),
          align = "hv",
          padding = 4,
          ncol = 2, nrow = 2)

#Plot densities for prior and posterior for varying alpha levels
ggarrange(p1 + rremove("x.text")+ rremove("xlab"), p2 + rremove("x.text")+ rremove("xlab")+ rremove("y.text") + rremove("ylab"), p3, p4 + rremove("y.text")+ rremove("ylab"),
          align = "hv",
          padding = 4,
          ncol = 2, nrow = 2)

```


**Looking at the recoveries**
```{r}
recovery_df
```


```{r}
#Plotting posterior predictions for different values of rulefollowing
post_preds_0.2 <- recovery_df_2[recovery_df_2$ruleFollowingTrue == 0.2, "ruleFollowingEst"]
colnames(post_preds_0.2)[1] = "pred_0.2"
post_preds_0.4 <- recovery_df_2[recovery_df_2$ruleFollowingTrue == 0.4, "ruleFollowingEst"]
colnames(post_preds_0.4)[1] = "pred_0.4"
post_preds_0.6 <- recovery_df_2[recovery_df_2$ruleFollowingTrue == "0.6", "ruleFollowingEst"]
colnames(post_preds_0.6)[1] = "pred_0.6"
post_preds_0.8 <- recovery_df_2[recovery_df_2$ruleFollowingTrue == 0.8, "ruleFollowingEst"]
colnames(post_preds_0.8)[1] = "pred_0.8"

df_post_preds <- cbind(post_preds_0.2, post_preds_0.4, post_preds_0.6, post_preds_0.8)


ggplot(df_post_preds) +
  geom_histogram(aes(pred_0.2), color = "yellow", fill = "lightyellow", alpha = 0.3, bins = 90) +
  geom_histogram(aes(pred_0.4), color = "green", fill = "lightgreen", alpha = 0.3, bins = 90) +
  geom_histogram(aes(pred_0.6), color = "blue", fill = "lightblue", alpha = 0.3, bins = 90) +
  geom_histogram(aes(pred_0.8), color = "pink", fill = "lightpink", alpha = 0.3, bins = 90) +
  #geom_point(x = sum(data$h), y = 0, color = "red", shape = 17, size = 5) +
  xlab("Estimated rule-following") +
  ylab("Posterior Density") +
  ggtitle("Posterior predictions for various rule-following values") + 
  annotate("text", x=0.1, y=300, label= "0.2") + 
  annotate("text", x=0.4, y=120, label= "0.4") +
  annotate("text", x=0.7, y=120, label= "0.6") +
  annotate("text", x=0.9, y=210, label= "0.8") +
  theme_classic()
```










