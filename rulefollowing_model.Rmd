
During this assignment you pick the model you have been working on and write a report:

- describing the model (you can re-use text from assignment 1, if relevant)
- showcasing a commented version of the stan model (what does each line do?)
- describing a process of parameter recovery (why are you doing it?, how are you doing it?)
- discussing the results: how many trials should be used at least to properly recover the parameters? what is the role of priors? Add relevant plot(s).

N.B. to pass it's enough to use the single agent model, but if you want to learn more (at the cost of more time investment), you could
- Build the multilevel version of your model and run the parameter recovery on it.
- Analyze an empirical dataset.

Empirical datasets:
- Guide to the data: https://www.dropbox.com/s/m1u5roo4z0f2emr/readme.txt?dl=0
- Non-human primates dataset: https://www.dropbox.com/s/8fj7k5jk8mn4j63/mp_primates.csv?dl=0
- Human primates dataset (former CogSci'ers): https://www.dropbox.com/s/9z6hcg9b4yhzgbu/mp_students.csv?dl=0
https://www.dropbox.com/s/r2ok23vjewyelaz/mp_students_22.csv?dl=0
- Clinical dataset (schizophrenia and controls): https://www.dropbox.com/s/dxj9f8txg1yax68/mp_schizophrenia.csv?dl=0

```{r}
library(rstan)
library(tidyverse)
library(reshape2)
library(ggdag)
library(ggplot2)
library(cmdstanr)
library(posterior)
library(brms)
library(boot)
theme_set(theme_dag())
```

https://ourcodingclub.github.io/tutorials/stan-intro/
https://vasishth.github.io/bayescogsci/book/ch-introstan.html


*TEST: For single game between WSLS / random*

**Defining the agents**
```{r}
#Attempt at changing it 
WSLSAgent_f <- function(prevChoice, Feedback, ruleFollowing) {
  if (ruleFollowing != 0){
    
    if (prevChoice == 0) {
      prevChoice == -1 }
  
    if (Feedback == 1) { #If feedback = 1 (win), stay
      rate = prevChoice*ruleFollowing
    }
    
    else if (Feedback == 0) { #If feedback = 0 (loss), shift
      rate = (-prevChoice)*ruleFollowing
    }
    
    rate = (1/2)*(rate + 1) #we needed -1 to become 0 and 1 to stay 1, also -0.5 will be 0.25 and 0.5 will be 0.75. 
  }
  
  else { rate = 0.5}
  
  choice <- rbinom(1, 1, rate)

  return(choice)
}


#Defining agent function
RandomAgent_f <- function(rate){
  choice <- rbinom(1, 1, rate)
  return(choice)
}

```


**Simulation**
```{r}
#Define rate
random_rate <- 0.5

#Define ruleFollowing
ruleFollowing <- 0.8

#Define number of trials
trials = 120

#Define empty vectors
Self <- rep(NA, trials)
Other <- rep(NA, trials)

#Define random first choice for player
Self[1] <- RandomAgent_f(0.5) #player

#Run simulation
for (t in seq(trials)){Other[t] <- RandomAgent_f(random_rate)}

for (i in 2:trials){
  if (Self[i-1] == Other[i-1]){
    Feedback = 1
} else {Feedback = 0}
  Self[i] <- WSLSAgent_f(Self[i-1], Feedback, ruleFollowing)
}

#show
df <- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other))
```


**Transforming the data to the appropriate form**
```{r}
#empty column
df$strategy_choice <- NA

#Transform
df$strategy_choice[df$Other == 1 & df$Self == 1] <- 1 #self wins on right, goes right
df$strategy_choice[df$Other == 1 & df$Self == 0] <- 1 #self loses on left, goes right
df$strategy_choice[df$Other == 0 & df$Self == 1] <- -1 #self loses on right, goes left
df$strategy_choice[df$Other == 0 & df$Self == 0] <- -1 #self wins on left, goes left

#df$Other[df$Other == 0 ] <- -1 #self wins on right, goes right
#df$Self[df$Self == 0] <- -1 

insert_value = NA

#shift strategy choice one down
df = df %>%
   mutate(strategy_choice = lag(strategy_choice, n = 1, default = insert_value))

#exclude first trial
df = df[-1,]

df$Feedback <- NA


#Transform to list
data <- list(
  n_trials = nrow(df),  # n of trials
  choice = df$Self, # sequence of choices
  strategy_choice = df$strategy_choice # whether or not agent is choosing right 
)

data
```


**Compile and fit the model**
```{r}
#collect stan model
file <- file.path("rulefollowing_agent.stan")
mod <- cmdstan_model(file, 
                     # this specifies we can parallelize the gradient estimations on multiple cores
                     cpp_options = list(stan_threads = TRUE), 
                     # this is a trick to make it faster
                     stanc_options = list("O1")) 

#extract samples
samples <- mod$sample(
  data = data, # the data :-)
  seed = 123,  # a seed, so I always get the same results
  chains = 2,  # how many chains should I fit (to check whether they give the same results)
  parallel_chains = 2, # how many of the chains can be run in parallel?
  threads_per_chain = 2, # distribute gradient estimations within chain across multiple cores
  iter_warmup = 1000,  # warmup iterations through which hyperparameters (steps and step length) are adjusted
  iter_sampling = 2000, # total number of iterations
  refresh = 0,  # how often to show that iterations have been run
  max_treedepth = 20, # how many steps in the future to check to avoid u-turns
  adapt_delta = 0.99, # how high a learning rate to adjust hyperparameters during warmup
)

#extract summary 
samples$summary()

samples$summary("ruleFollowing")

# Extract posterior samples and include sampling of the prior:
draws_df <- as_draws_df(samples$draws())

# Checking the model's chains (noise)
ggplot(draws_df, aes(.iteration,  ruleFollowing, group = .chain, color = .chain)) +
  geom_line() +
  theme_classic()

# Checking the model's chains (rate)
ggplot(draws_df, aes(.iteration, rate, group = .chain, color = .chain)) +
  geom_line() +
  theme_classic()

```



*Function for simulating with different values for rulefollowing*

```{r}
#Simulating with different values for ruleFollowing 
list_of_dfs <- list()
temp <- list()
recovery_df <- data.frame()

for(ruleFollowing_lvl in seq(0, 1, 0.2)){
  ruleFollowing = ruleFollowing_lvl
  trials = 120
  random_rate = 0.7
  
  #Define empty vectors
  Self <- rep(NA, trials)
  Other <- rep(NA, trials)
  
  #Define random first choice for player
  Self[1] <- RandomAgent_f(0.5) #player
  
  #Run simulation
  for (t in seq(trials)){Other[t] <- RandomAgent_f(random_rate)}
   
  for (i in 2:trials){
    if (Self[i-1] == Other[i-1]){
      Feedback = 1
  } else {Feedback = 0}
    Self[i] <- WSLSAgent_f(Self[i-1], Feedback, ruleFollowing)
  }

  #show
  df <- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other))
  
  list_of_dfs <- append(list_of_dfs, df)
  
  #empty column
  df$strategy_choice <- NA
  
  #Transform
  df$strategy_choice[df$Other == 1 & df$Self == 1] <- 1 #self wins on right, goes right
  df$strategy_choice[df$Other == 1 & df$Self == 0] <- 1 #self loses on left, goes right
  df$strategy_choice[df$Other == 0 & df$Self == 1] <- -1 #self loses on right, goes left
  df$strategy_choice[df$Other == 0 & df$Self == 0] <- -1 #self wins on left, goes left
  
  insert_value = NA
  
  #shift strategy choice one down
  df = df %>%
     mutate(strategy_choice = lag(strategy_choice, n = 1, default = insert_value))
  
  #exclude first trial
  df = df[-1,]
  
  #Transform to list
  data <- list(
    n_trials = nrow(df),  # n of trials
    choice = df$Self, # sequence of choices
    strategy_choice = df$strategy_choice # whether or not agent is choosing right 
    )
  
  file <- file.path("rulefollowing_agent.stan")
  mod <- cmdstan_model(file, 
                       # this specifies we can parallelize the gradient estimations on multiple cores
                       cpp_options = list(stan_threads = TRUE), 
                       # this is a trick to make it faster
                       stanc_options = list("O1")) 
  
  #extract samples
  samples <- mod$sample(
    data = data, # the data :-)
    seed = 123,  # a seed, so I always get the same results
    chains = 2,  # how many chains should I fit (to check whether they give the same results)
    parallel_chains = 2, # how many of the chains can be run in parallel?
    threads_per_chain = 2, # distribute gradient estimations within chain across multiple cores
    iter_warmup = 1000,  # warmup iterations through which hyperparameters (steps and step length) are adjusted
    iter_sampling = 2000, # total number of iterations
    refresh = 0,  # how often to show that iterations have been run
    max_treedepth = 20, # how many steps in the future to check to avoid u-turns
    adapt_delta = 0.99, # how high a learning rate to adjust hyperparameters during warmup
  )
  
  #extract summary 
  samples$summary()
  
  # Extract posterior samples and include sampling of the prior:
  draws_df <- as_draws_df(samples$draws())

  
  # Checking the model's chains (noise)
  temp = ggplot(draws_df, aes(.iteration,  ruleFollowing, group = .chain, color = .chain)) +
      geom_line() +
      theme_classic()
  
  # assign function within loop
  assign(paste0("plot_", ruleFollowing_lvl), temp)

  assign(paste0("draws_df_", ruleFollowing_lvl), draws_df)
  
  recovery_df <- rbind(recovery_df, samples$summary("ruleFollowing"))
  
  #assign(paste0("recovery_", ruleFollowing_lvl), samples$summary("ruleFollowing"))
  
}

  
```


**Plots for different values of rulefollowing**
```{r}
plot_0.2  <- plot_0.2 + ggtitle("Rule-following = 0.2")

# add a prior for theta (ugly, but we'll do better soon)
draws_df_0.2<- draws_df_0.2 %>% mutate(
  ruleFollowing_prior = rbeta(nrow(draws_df_0.2), 1, 1)
)

# Now let's plot the density for theta (prior and posterior)
p1 <- ggplot(draws_df_0.2) +
  geom_density(aes(ruleFollowing), fill = "blue", alpha = 0.3) +
  geom_density(aes(ruleFollowing_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.2, linetype = "dashed", color = "black", size = 1.5) +
  xlab("Rule-following") +
  ylab("Posterior Density") +
  ylim(0,5)+
  theme_classic()+
  ggtitle("True rule-following = 0.2")



plot_0.4 <- plot_0.4 + ggtitle("Rule-following = 0.4")

# add a prior for theta (ugly, but we'll do better soon)
draws_df_0.4<- draws_df_0.4 %>% mutate(
  ruleFollowing_prior = rbeta(nrow(draws_df_0.4), 1, 1)
)

# Now let's plot the density for theta (prior and posterior)
p2 <- ggplot(draws_df_0.4) +
  geom_density(aes(ruleFollowing), fill = "blue", alpha = 0.3) +
  geom_density(aes(ruleFollowing_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.4, linetype = "dashed", color = "black", size = 1.5) +
  xlab("Rule-following") +
  ylab("Posterior Density") +
  ylim(0,5)+
  theme_classic()+
  ggtitle("True rule-following = 0.4")


plot_0.6 <- plot_0.6 + ggtitle("Rule-following = 0.6")

# add a prior for theta (ugly, but we'll do better soon)
draws_df_0.6<- draws_df_0.6 %>% mutate(
  ruleFollowing_prior = rbeta(nrow(draws_df_0.6), 1, 1)
)

# Now let's plot the density for theta (prior and posterior)
p3 <- ggplot(draws_df_0.6) +
  geom_density(aes(ruleFollowing), fill = "blue", alpha = 0.3) +
  geom_density(aes(ruleFollowing_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.6, linetype = "dashed", color = "black", size = 1.5) +
  xlab("Rule-following") +
  ylab("Posterior Density") +
  ylim(0,5)+
  theme_classic()+
  ggtitle("True rule-following = 0.6")


plot_0.8 <- plot_0.8 + ggtitle("Rule-following = 0.8")

# add a prior for theta (ugly, but we'll do better soon)
draws_df_0.8<- draws_df_0.8 %>% mutate(
  ruleFollowing_prior = rbeta(nrow(draws_df_0.8), 1, 1)
)

# Now let's plot the density for theta (prior and posterior)
p4 <- ggplot(draws_df_0.8) +
  geom_density(aes(ruleFollowing), fill = "blue", alpha = 0.3) +
  geom_density(aes(ruleFollowing_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.8, linetype = "dashed", color = "black", size = 1.5) +
  xlab("Rule-following") +
  ylab("Posterior Density") +
  ylim(0,5)+
  theme_classic()+
  ggtitle("True rule-following = 0.8")



ggarrange(plot_0.2 + rremove("x.text")+ rremove("xlab"), plot_0.4 + rremove("x.text")+ rremove("xlab")+ rremove("y.text") + rremove("ylab"), plot_0.6, plot_0.8 + rremove("y.text")+ rremove("ylab"),
          align = "hv",
          padding = 4,
          ncol = 2, nrow = 2)

ggarrange(p1 + rremove("x.text")+ rremove("xlab"), p2 + rremove("x.text")+ rremove("xlab")+ rremove("y.text") + rremove("ylab"), p3, p4 + rremove("y.text")+ rremove("ylab"),
          align = "hv",
          padding = 4,
          ncol = 2, nrow = 2)


```


**Looking at the recoveries**
```{r}
recovery_df
```


Assessing prior and posterior predictions
```{r}
#THIS NEEDS A LOT OF LOVE! DOESNT WORK. RATE IS DIFFERENT PR. TRIAL SINCE IT IS LARGELY DETERMINED BY WHETHER LAST TRIAL WAS A WIN OR LOSS. 
# draws_df_0.2 <- draws_df_0.2 %>% mutate(
#   rate_prior = rbeta(nrow(draws_df_0.2), 1, 1))
# 
# ggplot(draws_df_0.2) +
#   geom_histogram(aes(rate_prior), color = "lightblue", fill = "blue", alpha = 0.3, bins = 90) +
#   geom_histogram(aes(rate_p), color = "darkblue", fill = "blue", alpha = 0.3, bins = 90) +
#   #geom_point(x = sum(data$choice), y = 0, color = "red", shape = 17, size = 5) +
#   xlab("Predicted heads out of 1000 trials") +
#   ylab("Posterior Density") +
#   theme_classic()


#IT IS POSSIBLE TO MAKE FOR RULEFOLLOWING, BUT I CANT FIGURE OUT IF IT MAKES SENCE RIGHT NOW

draws_df_0.2 <- draws_df_0.2 %>% mutate(
  ruleFollowing_prior = rbeta(nrow(draws_df_0.2), 1, 1))

ggplot(draws_df_0.2) +
  geom_histogram(aes(ruleFollowing_prior), color = "lightblue", fill = "blue", alpha = 0.3, bins = 90) +
  geom_histogram(aes(ruleFollowing), color = "darkblue", fill = "blue", alpha = 0.3, bins = 90) +
  #geom_point(x = sum(data$choice), y = 0, color = "red", shape = 17, size = 5) +
  xlab("Predicted heads out of 1000 trials") +
  ylab("Posterior Density") +
  theme_classic()
```














